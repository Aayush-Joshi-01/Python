{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRABcSOfNAye"
      },
      "source": [
        "# US - Baby Names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBcnMnVvNAyg"
      },
      "source": [
        "### Introduction:\n",
        "\n",
        "We are going to use a subset of [US Baby Names](https://www.kaggle.com/kaggle/us-baby-names) from Kaggle.  \n",
        "In the file it will be names from 2004 until 2014\n",
        "\n",
        "\n",
        "### Step 1. Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        },
        "id": "ZhOcwJlINAyh",
        "outputId": "16c31b5b-1c1f-450b-ab96-70d9e45d1a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,173 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [27.8 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,218 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,134 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,449 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,423 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,553 kB]\n",
            "Fetched 18.3 MB in 6s (2,815 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=4432246af58aacad889b3e57418815378678624b1f28d4383b5fc211b7cbfb63\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e735e96fac0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0440c9872004:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "! sudo apt update\n",
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "! wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "! tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "! pip install -q findspark\n",
        "! pip install pyspark\n",
        "! pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBjOtSLeNAyi"
      },
      "source": [
        "### Step 2. Import the dataset from this [address](https://raw.githubusercontent.com/guipsamora/pandas_exercises/master/06_Stats/US_Baby_Names/US_Baby_Names_right.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe4p9HPjNAyi"
      },
      "source": [
        "### Step 3. Assign it to a variable called baby_names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqGjfeYRNAyj",
        "outputId": "83a59601-0f86-4c07-d07a-0aad18730365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---------+----+------+-----+-----+\n",
            "|  _c0|   Id|     Name|Year|Gender|State|Count|\n",
            "+-----+-----+---------+----+------+-----+-----+\n",
            "|11349|11350|     Emma|2004|     F|   AK|   62|\n",
            "|11350|11351|  Madison|2004|     F|   AK|   48|\n",
            "|11351|11352|   Hannah|2004|     F|   AK|   46|\n",
            "|11352|11353|    Grace|2004|     F|   AK|   44|\n",
            "|11353|11354|    Emily|2004|     F|   AK|   41|\n",
            "|11354|11355|  Abigail|2004|     F|   AK|   37|\n",
            "|11355|11356|   Olivia|2004|     F|   AK|   33|\n",
            "|11356|11357| Isabella|2004|     F|   AK|   30|\n",
            "|11357|11358|   Alyssa|2004|     F|   AK|   29|\n",
            "|11358|11359|   Sophia|2004|     F|   AK|   28|\n",
            "|11359|11360|   Alexis|2004|     F|   AK|   27|\n",
            "|11360|11361|Elizabeth|2004|     F|   AK|   27|\n",
            "|11361|11362|   Hailey|2004|     F|   AK|   27|\n",
            "|11362|11363|     Anna|2004|     F|   AK|   26|\n",
            "|11363|11364|  Natalie|2004|     F|   AK|   25|\n",
            "|11364|11365|    Sarah|2004|     F|   AK|   25|\n",
            "|11365|11366|   Sydney|2004|     F|   AK|   25|\n",
            "|11366|11367|      Ava|2004|     F|   AK|   23|\n",
            "|11367|11368|  Trinity|2004|     F|   AK|   22|\n",
            "|11368|11369|    Haley|2004|     F|   AK|   21|\n",
            "+-----+-----+---------+----+------+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = spark.read.csv('US_Baby_Names_right.csv', header=True, inferSchema=True)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ1d3L69NAyj"
      },
      "source": [
        "### Step 4. See the first 10 entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfzz-oUsNAyj",
        "outputId": "fcc0e0f7-5d88-493b-f03d-b8557373b750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+--------+----+------+-----+-----+\n",
            "|  _c0|   Id|    Name|Year|Gender|State|Count|\n",
            "+-----+-----+--------+----+------+-----+-----+\n",
            "|11349|11350|    Emma|2004|     F|   AK|   62|\n",
            "|11350|11351| Madison|2004|     F|   AK|   48|\n",
            "|11351|11352|  Hannah|2004|     F|   AK|   46|\n",
            "|11352|11353|   Grace|2004|     F|   AK|   44|\n",
            "|11353|11354|   Emily|2004|     F|   AK|   41|\n",
            "|11354|11355| Abigail|2004|     F|   AK|   37|\n",
            "|11355|11356|  Olivia|2004|     F|   AK|   33|\n",
            "|11356|11357|Isabella|2004|     F|   AK|   30|\n",
            "|11357|11358|  Alyssa|2004|     F|   AK|   29|\n",
            "|11358|11359|  Sophia|2004|     F|   AK|   28|\n",
            "+-----+-----+--------+----+------+-----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xqog9OWNAyj"
      },
      "source": [
        "### Step 5. Delete the column 'Unnamed: 0' and 'Id'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg0eH6YNNAyk",
        "outputId": "a96fcd1e-5441-46ac-ae1a-19fb7e3ae90e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+------+-----+-----+\n",
            "|     Name|Year|Gender|State|Count|\n",
            "+---------+----+------+-----+-----+\n",
            "|     Emma|2004|     F|   AK|   62|\n",
            "|  Madison|2004|     F|   AK|   48|\n",
            "|   Hannah|2004|     F|   AK|   46|\n",
            "|    Grace|2004|     F|   AK|   44|\n",
            "|    Emily|2004|     F|   AK|   41|\n",
            "|  Abigail|2004|     F|   AK|   37|\n",
            "|   Olivia|2004|     F|   AK|   33|\n",
            "| Isabella|2004|     F|   AK|   30|\n",
            "|   Alyssa|2004|     F|   AK|   29|\n",
            "|   Sophia|2004|     F|   AK|   28|\n",
            "|   Alexis|2004|     F|   AK|   27|\n",
            "|Elizabeth|2004|     F|   AK|   27|\n",
            "|   Hailey|2004|     F|   AK|   27|\n",
            "|     Anna|2004|     F|   AK|   26|\n",
            "|  Natalie|2004|     F|   AK|   25|\n",
            "|    Sarah|2004|     F|   AK|   25|\n",
            "|   Sydney|2004|     F|   AK|   25|\n",
            "|      Ava|2004|     F|   AK|   23|\n",
            "|  Trinity|2004|     F|   AK|   22|\n",
            "|    Haley|2004|     F|   AK|   21|\n",
            "+---------+----+------+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = df.drop('_c0', 'Id')\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBqBmYSjNAyk"
      },
      "source": [
        "### Step 6. Is there more male or female names in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9NLBHJcNAyk",
        "outputId": "5369802f-d9b7-4d9d-98c8-e0370d944bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|Gender| count|\n",
            "+------+------+\n",
            "|     F|558846|\n",
            "|     M|457549|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy('Gender').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLnzsnQHNAyk"
      },
      "source": [
        "### Step 7. Group the dataset by name and assign to names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wv2FmyNJNAyk"
      },
      "outputs": [],
      "source": [
        "df.createOrReplaceTempView(\"baby_names\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baby_names = spark.sql(\"SELECT Name, SUM(Count) AS Count FROM baby_names GROUP BY Name\")\n",
        "baby_names.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibn9HM5LOMH2",
        "outputId": "2227b749-458a-49b7-d901-3846baaa6511"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+\n",
            "|    Name| Count|\n",
            "+--------+------+\n",
            "|   Kiana|  5965|\n",
            "|  Alayna| 14171|\n",
            "|   Ember|  3181|\n",
            "|   Tyler|129989|\n",
            "|  Maddox| 20716|\n",
            "|  Kellen|  6989|\n",
            "|  Heaven| 12277|\n",
            "|Julianne|  3465|\n",
            "| Susanna|  1250|\n",
            "|  Kenlee|   578|\n",
            "|    Kloe|  1359|\n",
            "|   Anyah|   472|\n",
            "|   Tegan|  2721|\n",
            "| Jazzlyn|  1173|\n",
            "|Brileigh|   130|\n",
            "|Analeigh|   505|\n",
            "|Kamarion|  1030|\n",
            "|   Aryan|  3322|\n",
            "| Galilea|  2641|\n",
            "|    Faye|  1211|\n",
            "+--------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_bJ4S_aNAyk"
      },
      "source": [
        "### Step 8. How many different names exist in the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKor_hiMNAyk",
        "outputId": "da49983d-9b94-48c5-fa05-54fd13e3d183"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17632"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "baby_names.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0_9Kz0cNAyk"
      },
      "source": [
        "### Step 9. What is the name with most occurrences?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buV42v-bNAyl",
        "outputId": "6f563bbf-8481-4656-fdb6-389db8d9ba2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "| Name| Count|\n",
            "+-----+------+\n",
            "|Jacob|242874|\n",
            "+-----+------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ],
      "source": [
        "baby_names.orderBy(F.desc('Count')).show(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiDNgQhZNAyl"
      },
      "source": [
        "### Step 10. How many different names have the least occurrences?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scZs32nINAyl",
        "outputId": "e1d8eb00-e8d3-4ba4-96ae-6372a2cd4744"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3682"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.groupBy('Name').count().filter(F.col('count') == 1).count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "627MjzzuNAyl"
      },
      "source": [
        "### Step 11. What is the median name occurrence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxGskSi7NAyl",
        "outputId": "766897cd-b714-4328-c045-5e96641d2fbf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.groupBy('Name').count().approxQuantile('count', [0.5], 0)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMhe9JMANAyl"
      },
      "source": [
        "### Step 12. What is the standard deviation of names?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuy00A9UNAyl",
        "outputId": "a712538a-5a12-492c-e64e-c060e388dd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "|     stddev(count)|\n",
            "+------------------+\n",
            "|122.02996350813885|\n",
            "+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.groupBy('Name').count().agg(F.stddev('count')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPDLEdp0NAyl"
      },
      "source": [
        "### Step 13. Get a summary with the mean, min, max, std and quartiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqbJ6iKBNAyl",
        "outputId": "846064c5-371d-4738-baea-1855425b35c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+------------------+-------+-------+-----------------+\n",
            "|summary|    Name|              Year| Gender|  State|            Count|\n",
            "+-------+--------+------------------+-------+-------+-----------------+\n",
            "|  count| 1016395|           1016395|1016395|1016395|          1016395|\n",
            "|   mean|Infinity|2009.0531899507573|   NULL|   NULL|34.85012421351935|\n",
            "| stddev|    NULL|3.1382928281812377|   NULL|   NULL|97.39734648617687|\n",
            "|    min|   Aaban|              2004|      F|     AK|                5|\n",
            "|    max|  Zyriah|              2014|      M|     WY|             4167|\n",
            "+-------+--------+------------------+-------+-------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.describe().show()"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}